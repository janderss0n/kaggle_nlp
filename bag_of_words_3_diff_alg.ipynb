{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./word2vec-nlp-tutorial/labeledTrainData.tsv', header=0,\n",
    "                   delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = train_test_split(data.index, test_size=0.20)\n",
    "train = data.iloc[split_index[0],:]\n",
    "validation = data.iloc[split_index[1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 3)\n",
      "(5000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'sentiment', 'review'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I gave it an 8 only because it had received such low votes... this is definitely really about a 5.5..... Ummm.. it was kind of bloody, had likeable, shallow characters, and it had some really hot babes in it. I like the eclectic killer, because he didn\\'t kill people the same way everytime... that sometimes gets old.\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0,:].review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download() #May be done once per computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(raw_text):\n",
    "    return BeautifulSoup(raw_text).get_text()\n",
    "\n",
    "\n",
    "def remove_non_english_letters(text):\n",
    "    return re.sub('[^A-Za-z]', ' ', text)\n",
    "\n",
    "\n",
    "def convert_to_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def split_text_into_individual_words(text):\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    def set_of_stopwords():\n",
    "        return set(stopwords.words('english'))\n",
    "    \n",
    "    english_stopwords = set_of_stopwords()\n",
    "    return [w for w in words if not w in english_stopwords]\n",
    "\n",
    "\n",
    "def words_to_one_string(words):\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def clean_and_process_text(raw_text):\n",
    "    text = remove_html(raw_text)\n",
    "    only_letters = remove_non_english_letters(text)\n",
    "    lower_case = convert_to_lower_case(only_letters)\n",
    "    words = split_text_into_individual_words(lower_case)\n",
    "    important_words = remove_stopwords(words)\n",
    "    return words_to_one_string(important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kaggle_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train['clean_review'] = train.review.apply(clean_and_process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>\"342_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I gave it an 8 only because it had received s...</td>\n",
       "      <td>gave received low votes definitely really ummm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>\"1842_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"This is my first movie review on IMDb. I was ...</td>\n",
       "      <td>first movie review imdb forced register watchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21359</th>\n",
       "      <td>\"2722_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"This recreation of the infamous 1959 murders ...</td>\n",
       "      <td>recreation infamous murders kansas based capot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10775</th>\n",
       "      <td>\"1515_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I watched the movie \\\"The Flock\\\" because of ...</td>\n",
       "      <td>watched movie flock casting gere danes story s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23244</th>\n",
       "      <td>\"7486_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"In an apparent attempt to avoid remaking the ...</td>\n",
       "      <td>apparent attempt avoid remaking original movie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  sentiment                                             review  \\\n",
       "5276   \"342_10\"          1  \"I gave it an 8 only because it had received s...   \n",
       "2224   \"1842_1\"          0  \"This is my first movie review on IMDb. I was ...   \n",
       "21359  \"2722_8\"          1  \"This recreation of the infamous 1959 murders ...   \n",
       "10775  \"1515_1\"          0  \"I watched the movie \\\"The Flock\\\" because of ...   \n",
       "23244  \"7486_4\"          0  \"In an apparent attempt to avoid remaking the ...   \n",
       "\n",
       "                                            clean_review  \n",
       "5276   gave received low votes definitely really ummm...  \n",
       "2224   first movie review imdb forced register watchi...  \n",
       "21359  recreation infamous murders kansas based capot...  \n",
       "10775  watched movie flock casting gere danes story s...  \n",
       "23244  apparent attempt avoid remaking original movie...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features from Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',\n",
    "                            tokenizer=None,\n",
    "                            preprocessor=None,\n",
    "                            stop_words=None,\n",
    "                            max_features=5000)\n",
    "train_features = vectorizer.fit_transform(train['clean_review'])\n",
    "train_features = pd.DataFrame(train_features.toarray())\n",
    "train_features.columns = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abraham</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>zero</th>\n",
       "      <th>zizek</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandoned  abc  abilities  ability  able  abraham  absence  absent  \\\n",
       "0          0    0          0        0     0        0        0       0   \n",
       "1          0    0          0        0     0        0        0       0   \n",
       "2          0    0          0        0     0        0        0       0   \n",
       "3          0    0          0        0     0        0        0       0   \n",
       "4          0    0          0        0     0        0        0       0   \n",
       "\n",
       "   absolute  absolutely  ...  yet  york  young  younger  youth  zero  zizek  \\\n",
       "0         0           0  ...    0     0      0        0      0     0      0   \n",
       "1         0           0  ...    1     0      0        0      0     1      0   \n",
       "2         0           0  ...    0     0      0        0      0     0      0   \n",
       "3         0           0  ...    0     0      0        0      0     1      0   \n",
       "4         0           0  ...    0     0      0        0      0     0      0   \n",
       "\n",
       "   zombie  zombies  zone  \n",
       "0       0        0     0  \n",
       "1       0        0     0  \n",
       "2       0        0     0  \n",
       "3       0        0     0  \n",
       "4       0        0     0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abandoned        153\n",
       "abc               99\n",
       "abilities         90\n",
       "ability          374\n",
       "able            1022\n",
       "abraham           69\n",
       "absence           94\n",
       "absent            65\n",
       "absolute         284\n",
       "absolutely      1202\n",
       "absurd           249\n",
       "absurdity         63\n",
       "abuse            147\n",
       "abusive           74\n",
       "abysmal           79\n",
       "academy          227\n",
       "accent           402\n",
       "accents          162\n",
       "accept           237\n",
       "acceptable       105\n",
       "accepted         119\n",
       "access            76\n",
       "accident         252\n",
       "accidentally     166\n",
       "accompanied       66\n",
       "accomplish        64\n",
       "accomplished     107\n",
       "according        240\n",
       "account          149\n",
       "accurate         225\n",
       "                ... \n",
       "wretched          69\n",
       "write            530\n",
       "writer           926\n",
       "writers          540\n",
       "writes            74\n",
       "writing         1036\n",
       "written         1264\n",
       "wrong           1459\n",
       "wrote            459\n",
       "ww                70\n",
       "wwii             124\n",
       "ya                78\n",
       "yard              64\n",
       "yeah             361\n",
       "year            1911\n",
       "years           3588\n",
       "yelling           73\n",
       "yellow            84\n",
       "yes             1205\n",
       "yesterday         92\n",
       "yet             2210\n",
       "york             649\n",
       "young           2993\n",
       "younger          419\n",
       "youth            224\n",
       "zero             314\n",
       "zizek             63\n",
       "zombie           599\n",
       "zombies          416\n",
       "zone             117\n",
       "Length: 5000, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import r2_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest_model = forest.fit(train_features, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kaggle_nlp/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = SVC()\n",
    "svc_model = svm_classifier.fit(train_features, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mNB = MultinomialNB()\n",
    "mNB_model = mNB.fit(train_features, train['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kaggle_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "validation['clean_review'] = validation.review.apply(clean_and_process_text)\n",
    "validation_features = vectorizer.transform(validation['clean_review'])\n",
    "validation_features = pd.DataFrame(validation_features.toarray())\n",
    "validation_features.columns = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abraham</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>zero</th>\n",
       "      <th>zizek</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandoned  abc  abilities  ability  able  abraham  absence  absent  \\\n",
       "0          0    0          0        0     0        0        0       0   \n",
       "1          0    0          0        0     0        0        0       0   \n",
       "2          0    0          0        0     0        0        0       0   \n",
       "3          0    0          0        0     0        0        0       0   \n",
       "4          0    0          0        0     0        0        0       0   \n",
       "\n",
       "   absolute  absolutely  ...  yet  york  young  younger  youth  zero  zizek  \\\n",
       "0         0           0  ...    0     0      0        0      0     0      0   \n",
       "1         0           0  ...    0     0      0        0      0     0      0   \n",
       "2         0           0  ...    0     0      0        0      0     0      0   \n",
       "3         0           0  ...    0     0      0        0      0     0      0   \n",
       "4         0           0  ...    1     0      0        0      0     0      0   \n",
       "\n",
       "   zombie  zombies  zone  \n",
       "0       0        0     0  \n",
       "1       0        0     0  \n",
       "2       0        0     0  \n",
       "3       0        0     0  \n",
       "4       0        0     0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_result = forest_model.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_result = svc_model.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mNB_result = mNB_model.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3751879036378146\n",
      "[[2150  361]\n",
      " [ 420 2069]]\n",
      "0.3455873305707201\n",
      "[[1971  540]\n",
      " [ 278 2211]]\n",
      "0.3959883063336108\n",
      "[[2172  339]\n",
      " [ 416 2073]]\n"
     ]
    }
   ],
   "source": [
    "for result in [forest_result, svc_result, mNB_result]:\n",
    "    print(r2_score(validation.sentiment, result))\n",
    "    print(confusion_matrix(validation.sentiment, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
